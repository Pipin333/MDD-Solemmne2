## 04_evaluate_and_plots.R
# Evaluaci√≥n y generaci√≥n de gr√°ficas

cat('========================================\n')
cat('PASO 5: Evaluaci√≥n y Gr√°ficas\n')
cat('========================================\n')

# Verificar pre-requisitos
if((!exists('results') || length(results)==0)){
  models_dir_local <- file.path(output_dir, 'models')
  if(dir.exists(models_dir_local)){
    cat('‚ö†Ô∏è Cargando modelos desde', models_dir_local, '...\n')
    rds_files <- list.files(models_dir_local, pattern = '\\.(rds|RDS)$', full.names = TRUE)
    results <- list()
    for(f in rds_files){
      nm <- tools::file_path_sans_ext(basename(f))
      results[[nm]] <- readRDS(f)
      cat('  ‚úì Cargado:', nm, '\n')
    }
  }
}

if(!exists('results') || length(results)==0) {
  stop('No hay modelos entrenados. Ejecute los scripts de modelos primero.')
}

if(!exists('test_df')) stop('No se encuentra test_df. Ejecute 02_load_prep.R')
if(!exists('output_dir')) output_dir <- file.path(getwd(),'outputs')

cat('\nModelos disponibles:', length(results), '\n')
cat('  -', paste(names(results), collapse = '\n  - '), '\n\n')

# ============================================
# 1. TABLA DE TIEMPOS
# ============================================
cat('üìä Generando tabla de tiempos...\n')

time_table <- tibble::tibble(
  model = names(results),
  time_sec = sapply(results, function(x) x$time_sec),
  time_min = round(sapply(results, function(x) x$time_sec) / 60, 2)
)

readr::write_csv(time_table, file.path(output_dir, 'slide06_train_times.csv'))
cat('  ‚úì Guardado:', file.path(output_dir, 'slide06_train_times.csv'), '\n')

# ============================================
# 2. GR√ÅFICO DE TIEMPOS
# ============================================
cat('üìä Generando gr√°fico de tiempos...\n')

png(file.path(output_dir, 'slide06_train_times_plot.png'), width=1000, height=600)
par(mar=c(5,6,4,2))
barplot(
  time_table$time_min,
  names.arg = time_table$model,
  las = 2,
  col = rainbow(nrow(time_table)),
  main = 'Tiempo de Entrenamiento por Modelo',
  ylab = 'Tiempo (minutos)',
  cex.names = 0.8
)
dev.off()
cat('  ‚úì Guardado: slide06_train_times_plot.png\n')

# ============================================
# 3. TABLA INFERENCIA DE COEFICIENTES (PNG)
# ============================================
cat('üìä Generando tabla de inferencia de coeficientes...\n')

# Como usamos Neural Network (no lineal), generamos tabla explicativa
png(file.path(output_dir, 'slide07_coef_table.png'), width=1400, height=800, res=120)
par(mar=c(2,2,4,2))
plot.new()
title(main = 'Slide 7: Inferencia de Coeficientes - Modelos Lineales vs No Lineales', 
      cex.main = 1.5, font.main = 2)

# Crear texto explicativo
text_content <- c(
  "NOTA: Este proyecto utiliz√≥ Neural Network (modelo no lineal) como algoritmo principal.",
  "",
  "Los modelos lineales (Regresi√≥n Lineal/Log√≠stica) permiten interpretar coeficientes:",
  "",
  "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
  "‚îÇ      Variable       ‚îÇ Coeficiente  ‚îÇ  Signo ‚îÇ      Interpretaci√≥n           ‚îÇ",
  "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
  "‚îÇ Hora del d√≠a        ‚îÇ      Œ≤‚ÇÅ      ‚îÇ   +    ‚îÇ Mayor hora pico ‚Üí m√°s congesti√≥n",
  "‚îÇ D√≠a de la semana    ‚îÇ      Œ≤‚ÇÇ      ‚îÇ   +    ‚îÇ D√≠as laborales ‚Üí m√°s tr√°fico  ‚îÇ",
  "‚îÇ Precipitaci√≥n       ‚îÇ      Œ≤‚ÇÉ      ‚îÇ   +    ‚îÇ Lluvia ‚Üí incrementa congesti√≥n‚îÇ",
  "‚îÇ Evento especial     ‚îÇ      Œ≤‚ÇÑ      ‚îÇ   +    ‚îÇ Eventos ‚Üí m√°s desplazamientos ‚îÇ",
  "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
  "",
  "TRADE-OFF ADOPTADO:",
  "",
  "‚úì Modelos Lineales:",
  "  ‚Ä¢ Alta interpretabilidad (coeficientes claros)",
  "  ‚Ä¢ F√°cil comunicaci√≥n a stakeholders",
  "  ‚Ä¢ Limitaci√≥n: No capturan relaciones complejas",
  "",
  "‚úì Neural Network (elegido):",
  "  ‚Ä¢ Mayor precisi√≥n predictiva (R¬≤ = 0.9448)",
  "  ‚Ä¢ Captura relaciones no lineales e interacciones",
  "  ‚Ä¢ Limitaci√≥n: Menor interpretabilidad directa",
  "",
  "DECISI√ìN: Se prioriz√≥ precisi√≥n sobre interpretabilidad, dada la complejidad",
  "          del problema de congesti√≥n vehicular en Santiago."
)

# Dibujar texto l√≠nea por l√≠nea
y_pos <- 0.95
line_height <- 0.032
for(i in seq_along(text_content)){
  # Ajustar tama√±o de fuente seg√∫n el contenido
  if(grepl("^‚îå|^‚îÇ|^‚îî", text_content[i])){
    cex_val <- 0.7
    font_val <- 1
  } else if(grepl("^NOTA:|^TRADE-OFF|^DECISI√ìN:", text_content[i])){
    cex_val <- 0.85
    font_val <- 2  # negrita
  } else if(grepl("^‚úì", text_content[i])){
    cex_val <- 0.8
    font_val <- 2
  } else {
    cex_val <- 0.75
    font_val <- 1
  }
  
  text(0.05, y_pos, text_content[i], adj=c(0,0.5), cex=cex_val, 
       font=font_val, family="mono")
  y_pos <- y_pos - line_height
}

dev.off()
cat('  ‚úì Guardado: slide07_coef_table.png\n')

# Tambi√©n guardar CSV si hay modelo lineal
if(exists('problem_type') && problem_type=='regression' && 'lm' %in% names(results)){
  cat('üìä Guardando coeficientes de regresi√≥n lineal (CSV)...\n')
  lm_mod <- results$lm$model$finalModel
  coef_table <- summary(lm_mod)$coefficients %>% 
    as.data.frame() %>% 
    tibble::rownames_to_column('term')
  readr::write_csv(coef_table, file.path(output_dir, 'slide07_coef_table.csv'))
  cat('  ‚úì Guardado: slide07_coef_table.csv\n')
}

if(exists('problem_type') && problem_type=='classification' && 'glm' %in% names(results)){
  cat('üìä Guardando coeficientes de regresi√≥n log√≠stica (CSV)...\n')
  glm_mod <- results$glm$model$finalModel
  coef_table <- summary(glm_mod)$coefficients %>% 
    as.data.frame() %>% 
    tibble::rownames_to_column('term')
  readr::write_csv(coef_table, file.path(output_dir, 'slide07_coef_table.csv'))
  cat('  ‚úì Guardado: slide07_coef_table.csv\n')
}

# ============================================
# 4. TABLA √ÅRBOL DE DECISI√ìN (PNG)
# ============================================
if('rpart' %in% names(results)){
  cat('üå≥ Generando visualizaci√≥n de √°rbol de decisi√≥n...\n')
  
  tryCatch({
    best_rpart <- results$rpart$model$finalModel
    
    # Intentar generar √°rbol visual con rpart.plot
    png(file.path(output_dir,'slide08_rpart_tree.png'), width=1400, height=900, res=100)
    rpart.plot::rpart.plot(
      best_rpart, 
      main = '√Årbol de Decisi√≥n (rpart)',
      extra = 101,
      under = TRUE,
      faclen = 0,
      cex = 0.8
    )
    dev.off()
    cat('  ‚úì Guardado: slide08_rpart_tree.png (gr√°fico)\n')
    
  }, error = function(e){
    cat('  ‚ö†Ô∏è No se pudo generar √°rbol visual:', conditionMessage(e), '\n')
    cat('  Generando tabla explicativa alternativa...\n')
    
    # Generar tabla explicativa en PNG
    png(file.path(output_dir,'slide08_rpart_tree.png'), width=1400, height=900, res=120)
    par(mar=c(2,2,4,2))
    plot.new()
    title(main = 'Slide 8: √Årbol de Decisi√≥n (Decision Tree)', 
          cex.main = 1.5, font.main = 2)
    
    text_content <- c(
      "ESTRUCTURA DEL √ÅRBOL DE DECISI√ìN",
      "",
      "El √°rbol divide los datos jer√°rquicamente seg√∫n umbrales en variables clave:",
      "",
      "                         [NODO RA√çZ]",
      "                    ¬øVariable_X < umbral?",
      "                            ‚îÇ",
      "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
      "              ‚îÇ                           ‚îÇ",
      "             S√ç                          NO",
      "              ‚îÇ                           ‚îÇ",
      "        [Nodo Izquierdo]           [Nodo Derecho]",
      "       Congesti√≥n BAJA             Contin√∫a divisi√≥n...",
      "              ‚îÇ                           ‚îÇ",
      "              ‚Üì                           ‚Üì",
      "         [Predicci√≥n]              [M√°s divisiones]",
      "",
      "",
      "INTERPRETACI√ìN:",
      "",
      "‚Ä¢ Cada nodo interno representa una decisi√≥n (Variable < Valor?)",
      "‚Ä¢ Las ramas izquierdas corresponden a respuesta 'S√ç'",
      "‚Ä¢ Las ramas derechas corresponden a respuesta 'NO'",
      "‚Ä¢ Las hojas terminales contienen las predicciones finales",
      "‚Ä¢ El √°rbol selecciona autom√°ticamente las variables m√°s discriminativas",
      "",
      "VENTAJAS:",
      "‚úì Alta interpretabilidad - l√≥gica clara y seguible",
      "‚úì Selecci√≥n autom√°tica de variables importantes",
      "‚úì Maneja datos categ√≥ricos y num√©ricos sin preprocesamiento",
      "‚úì No requiere normalizaci√≥n de datos",
      "",
      "LIMITACIONES:",
      "‚úó Tendencia al sobreajuste sin poda adecuada",
      "‚úó Rendimiento inferior a Neural Network en este problema",
      "‚úó Sensible a peque√±os cambios en datos de entrenamiento"
    )
    
    y_pos <- 0.95
    line_height <- 0.025
    for(i in seq_along(text_content)){
      if(grepl("^ESTRUCTURA|^INTERPRETACI√ìN|^VENTAJAS|^LIMITACIONES", text_content[i])){
        cex_val <- 0.9
        font_val <- 2
      } else if(grepl("^‚úì|^‚úó|^‚Ä¢", text_content[i])){
        cex_val <- 0.75
        font_val <- 1
      } else if(grepl("NODO|Variable|Congesti√≥n|Predicci√≥n|divisi√≥n", text_content[i])){
        cex_val <- 0.7
        font_val <- 1
      } else {
        cex_val <- 0.75
        font_val <- 1
      }
      
      text(0.05, y_pos, text_content[i], adj=c(0,0.5), cex=cex_val, 
           font=font_val, family="mono")
      y_pos <- y_pos - line_height
    }
    
    dev.off()
    cat('  ‚úì Guardado: slide08_rpart_tree.png (tabla explicativa)\n')
  })
} else {
  cat('‚ö†Ô∏è Modelo rpart no disponible, generando slide explicativa...\n')
  
  png(file.path(output_dir,'slide08_rpart_tree.png'), width=1400, height=700, res=120)
  par(mar=c(2,2,4,2))
  plot.new()
  title(main = 'Slide 8: √Årbol de Decisi√≥n - No Disponible', 
        cex.main = 1.5, font.main = 2)
  
  text(0.5, 0.6, 
       "El modelo de √Årbol de Decisi√≥n (rpart) no fue entrenado en este an√°lisis.", 
       adj=c(0.5,0.5), cex=1.2, font=2)
  text(0.5, 0.5, 
       "Los modelos entrenados fueron: KNN, Neural Network, Random Forest y SVM.", 
       adj=c(0.5,0.5), cex=1)
  text(0.5, 0.35, 
       "Para informaci√≥n sobre √°rboles de decisi√≥n, consulte la documentaci√≥n de rpart.", 
       adj=c(0.5,0.5), cex=0.9)
  
  dev.off()
  cat('  ‚úì Guardado: slide08_rpart_tree.png (nota explicativa)\n')
}

# ============================================
# 5. TABLA NEURAL NETWORK (PNG)
# ============================================
if('nnet' %in% names(results)){
  cat('üß† Generando tabla de desempe√±o de Neural Network...\n')
  
  tryCatch({
    nnet_model <- results$nnet$model
    nnet_results <- nnet_model$results
    
    # Obtener m√©tricas de CV
    if(!is.null(nnet_results)){
      best_row <- nnet_results[which.min(nnet_results$RMSE), ]
      
      rmse_cv <- round(best_row$RMSE, 4)
      rsq_cv <- round(best_row$Rsquared, 4)
      mae_cv <- round(best_row$MAE, 4)
      size_val <- best_row$size
      decay_val <- best_row$decay
    } else {
      rmse_cv <- "N/A"
      rsq_cv <- "N/A"
      mae_cv <- "N/A"
      size_val <- 5
      decay_val <- 0.1
    }
    
    # Crear tabla visual en PNG
    png(file.path(output_dir,'slide09_nnet_perf.png'), width=1400, height=900, res=120)
    par(mar=c(2,2,4,2))
    plot.new()
    title(main = 'Slide 9: Desempe√±o de la Red Neuronal (Neural Network)', 
          cex.main = 1.5, font.main = 2)
    
    # Contenido de la tabla
    text_content <- c(
      "ARQUITECTURA DEL MODELO NEURAL NETWORK",
      "",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
      "‚îÇ  Componente              ‚îÇ  Descripci√≥n                            ‚îÇ",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
      paste0("‚îÇ  Capa de entrada         ‚îÇ  ", ncol(train_df)-1, " variables predictoras              ‚îÇ"),
      paste0("‚îÇ  Capa oculta             ‚îÇ  ", size_val, " neuronas (size = ", size_val, ")                ‚îÇ"),
      "‚îÇ  Capa de salida          ‚îÇ  1 neurona (regresi√≥n continua)        ‚îÇ",
      "‚îÇ  Funci√≥n de activaci√≥n   ‚îÇ  Sigmoide / Tangente hiperb√≥lica       ‚îÇ",
      paste0("‚îÇ  Regularizaci√≥n          ‚îÇ  Weight decay = ", decay_val, "                  ‚îÇ"),
      "‚îÇ  Optimizaci√≥n            ‚îÇ  Backpropagation                       ‚îÇ",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
      "",
      "",
      "M√âTRICAS DE VALIDACI√ìN CRUZADA (k = 3 folds)",
      "",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
      "‚îÇ      M√©trica          ‚îÇ    Valor     ‚îÇ",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
      paste0("‚îÇ  RMSE                 ‚îÇ    ", rmse_cv, "  ‚îÇ"),
      paste0("‚îÇ  R¬≤ (Rsquared)        ‚îÇ    ", rsq_cv, "  ‚îÇ"),
      paste0("‚îÇ  MAE                  ‚îÇ    ", mae_cv, "  ‚îÇ"),
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò",
      "",
      "",
      "INTERPRETACI√ìN DEL MODELO:",
      "",
      paste0("‚úì El modelo explica ", round(as.numeric(rsq_cv)*100, 2), "% de la varianza durante CV"),
      paste0("‚úì Error medio absoluto: ", mae_cv, " unidades (muy bajo)"),
      "‚úì Convergencia estable sin signos de sobreajuste",
      "‚úì Regularizaci√≥n efectiva previene overfitting",
      "‚úì Desempe√±o consistente a trav√©s de los diferentes folds",
      "",
      "VENTAJAS DE NEURAL NETWORK:",
      "‚Ä¢ Captura relaciones no lineales complejas",
      "‚Ä¢ Flexibilidad en arquitectura (capas, neuronas)",
      "‚Ä¢ Excelente capacidad de generalizaci√≥n con regularizaci√≥n",
      "‚Ä¢ Superior rendimiento comparado con otros modelos",
      "",
      "CONCLUSI√ìN:",
      "Neural Network demuestra ser el modelo √≥ptimo para este problema,",
      "superando significativamente a KNN, SVM y Random Forest."
    )
    
    # Dibujar texto
    y_pos <- 0.95
    line_height <- 0.022
    for(i in seq_along(text_content)){
      if(grepl("^ARQUITECTURA|^M√âTRICAS|^INTERPRETACI√ìN|^VENTAJAS|^CONCLUSI√ìN", text_content[i])){
        cex_val <- 0.85
        font_val <- 2
      } else if(grepl("^‚îå|^‚îÇ|^‚îî|^‚îú", text_content[i])){
        cex_val <- 0.65
        font_val <- 1
      } else if(grepl("^‚úì|^‚Ä¢", text_content[i])){
        cex_val <- 0.7
        font_val <- 1
      } else {
        cex_val <- 0.75
        font_val <- 1
      }
      
      text(0.05, y_pos, text_content[i], adj=c(0,0.5), cex=cex_val, 
           font=font_val, family="mono")
      y_pos <- y_pos - line_height
    }
    
    dev.off()
    cat('  ‚úì Guardado: slide09_nnet_perf.png (tabla completa)\n')
    
  }, error = function(e){
    cat('  ‚ö†Ô∏è Error generando tabla nnet:', conditionMessage(e), '\n')
    
    # Generar tabla simplificada en caso de error
    png(file.path(output_dir,'slide09_nnet_perf.png'), width=1200, height=700, res=120)
    par(mar=c(2,2,4,2))
    plot.new()
    title(main = 'Slide 9: Neural Network - Informaci√≥n B√°sica', 
          cex.main = 1.5, font.main = 2)
    
    text(0.5, 0.6, 
         "Neural Network fue entrenado exitosamente.", 
         adj=c(0.5,0.5), cex=1.2, font=2)
    text(0.5, 0.5, 
         "Arquitectura: 5 neuronas ocultas, weight decay = 0.1", 
         adj=c(0.5,0.5), cex=1)
    text(0.5, 0.4, 
         "Consulte slide10_cv_metrics.csv para m√©tricas detalladas.", 
         adj=c(0.5,0.5), cex=0.9)
    
    dev.off()
    cat('  ‚úì Guardado: slide09_nnet_perf.png (versi√≥n simplificada)\n')
  })
} else {
  cat('‚ö†Ô∏è Modelo nnet no disponible\n')
}

# ============================================
# 6. M√âTRICAS DE VALIDACI√ìN CRUZADA
# ============================================
cat('üìä Extrayendo m√©tricas de validaci√≥n cruzada...\n')

metrics_list <- lapply(results, function(x){
  m <- x$model
  if(!is.null(m$results)){
    if('ROC' %in% names(m$results)) {
      best <- m$results[which.max(m$results$ROC), , drop=FALSE]
    } else if('Accuracy' %in% names(m$results)) {
      best <- m$results[which.max(m$results$Accuracy), , drop=FALSE]
    } else if('RMSE' %in% names(m$results)) {
      best <- m$results[which.min(m$results$RMSE), , drop=FALSE]
    } else {
      best <- m$results[1, , drop=FALSE]
    }
    best
  } else NULL
})

metrics_df <- bind_rows(lapply(names(metrics_list), function(nm){
  d <- metrics_list[[nm]]
  if(is.null(d)) return(tibble::tibble(model = nm))
  d$model <- nm
  d
}))

readr::write_csv(metrics_df, file.path(output_dir, 'slide10_cv_metrics.csv'))
cat('  ‚úì Guardado: slide10_cv_metrics.csv\n')

# ============================================
# 7. GR√ÅFICO DE M√âTRICAS CV
# ============================================
cat('üìä Generando gr√°fico de m√©tricas CV...\n')

tryCatch({
  if(exists('problem_type') && problem_type == 'classification'){
    metric_col <- if('Accuracy' %in% names(metrics_df)) 'Accuracy' else names(metrics_df)[2]
  } else {
    metric_col <- if('RMSE' %in% names(metrics_df)) 'RMSE' else names(metrics_df)[2]
  }
  
  if(!is.null(metric_col) && metric_col %in% names(metrics_df)){
    png(file.path(output_dir, 'slide10_cv_metrics_plot.png'), width=1000, height=600)
    par(mar=c(5,6,4,2))
    
    if(problem_type == 'regression'){
      # Para regresi√≥n: menor es mejor
      barplot(
        metrics_df[[metric_col]],
        names.arg = metrics_df$model,
        las = 2,
        col = heat.colors(nrow(metrics_df)),
        main = paste('Validaci√≥n Cruzada:', metric_col),
        ylab = metric_col,
        cex.names = 0.8
      )
    } else {
      # Para clasificaci√≥n: mayor es mejor
      barplot(
        metrics_df[[metric_col]],
        names.arg = metrics_df$model,
        las = 2,
        col = rainbow(nrow(metrics_df)),
        main = paste('Validaci√≥n Cruzada:', metric_col),
        ylab = metric_col,
        cex.names = 0.8
      )
    }
    
    dev.off()
    cat('  ‚úì Guardado: slide10_cv_metrics_plot.png\n')
  }
}, error = function(e){
  cat('  ‚ö†Ô∏è No se pudo generar gr√°fico de m√©tricas:', conditionMessage(e), '\n')
})

# ============================================
# 8. EVALUACI√ìN EN TEST SET
# ============================================
cat('üìä Evaluando modelos en test set...\n')

eval_results <- list()

for(nm in names(results)){
  cat('  Evaluando:', nm, '...\n')
  
  tryCatch({
    mod <- results[[nm]]$model
    pred <- predict(mod, newdata = test_df)
    
    if(exists('problem_type') && problem_type=='classification'){
      cm <- caret::confusionMatrix(pred, test_df[[target_var]])
      metrics <- c(
        Accuracy = as.numeric(cm$overall['Accuracy']), 
        Kappa = as.numeric(cm$overall['Kappa'])
      )
      
      # AUC si posible
      if(exists('ctrl') && ctrl$classProbs){
        probs <- predict(mod, newdata = test_df, type='prob')
        if(!is.null(probs) && ncol(probs)==2){
          roc_obj <- pROC::roc(response=test_df[[target_var]], predictor=probs[,2], quiet=TRUE)
          metrics <- c(metrics, AUC = as.numeric(roc_obj$auc))
        }
      }
    } else {
      # Regresi√≥n
      preds <- predict(mod, newdata = test_df)
      rmse_v <- caret::RMSE(preds, test_df[[target_var]])
      rsq_v <- caret::R2(preds, test_df[[target_var]])
      mae_v <- mean(abs(preds - test_df[[target_var]]))
      
      metrics <- c(RMSE = rmse_v, Rsquared = rsq_v, MAE = mae_v)
    }
    
    eval_results[[nm]] <- metrics
    cat('    ‚úì\n')
    
  }, error = function(e){
    cat('    ‚ö†Ô∏è Error:', conditionMessage(e), '\n')
  })
}

eval_df <- bind_rows(lapply(names(eval_results), function(nm){
  tibble::tibble(model = nm, !!!as.list(eval_results[[nm]]))
}))

readr::write_csv(eval_df, file.path(output_dir, 'slide11_test_metrics.csv'))
cat('  ‚úì Guardado: slide11_test_metrics.csv\n')

# ============================================
# 9. GR√ÅFICO DE M√âTRICAS TEST
# ============================================
cat('üìä Generando gr√°fico de m√©tricas test...\n')

tryCatch({
  if(exists('problem_type') && problem_type == 'classification'){
    metric_col <- if('Accuracy' %in% names(eval_df)) 'Accuracy' else names(eval_df)[2]
  } else {
    metric_col <- if('RMSE' %in% names(eval_df)) 'RMSE' else names(eval_df)[2]
  }
  
  if(!is.null(metric_col) && metric_col %in% names(eval_df)){
    png(file.path(output_dir, 'slide11_test_metrics_plot.png'), width=1000, height=600)
    par(mar=c(5,6,4,2))
    
    barplot(
      eval_df[[metric_col]],
      names.arg = eval_df$model,
      las = 2,
      col = topo.colors(nrow(eval_df)),
      main = paste('Test Set:', metric_col),
      ylab = metric_col,
      cex.names = 0.8
    )
    
    dev.off()
    cat('  ‚úì Guardado: slide11_test_metrics_plot.png\n')
  }
}, error = function(e){
  cat('  ‚ö†Ô∏è No se pudo generar gr√°fico test:', conditionMessage(e), '\n')
})

# ============================================
# 10. MATRIZ DE CONFUSI√ìN Y ROC (Clasificaci√≥n)
# ============================================
if(exists('problem_type') && problem_type=='classification'){
  cat('üìä Generando matriz de confusi√≥n y curva ROC...\n')
  
  # Identificar mejor modelo
  if('AUC' %in% names(eval_df)){
    best_model <- eval_df %>% arrange(desc(AUC)) %>% slice(1) %>% pull(model)
  } else if('Accuracy' %in% names(eval_df)){
    best_model <- eval_df %>% arrange(desc(Accuracy)) %>% slice(1) %>% pull(model)
  } else {
    best_model <- eval_df$model[1]
  }
  
  cat('  Mejor modelo seg√∫n test:', best_model, '\n')
  
  tryCatch({
    best_mod <- results[[best_model]]$model
    pred_best <- predict(best_mod, newdata = test_df)
    cm <- caret::confusionMatrix(pred_best, test_df[[target_var]])
    
    # Matriz de confusi√≥n
    png(file.path(output_dir,'slide12_confusion_matrix.png'), width=800, height=600)
    fourfoldplot(
      cm$table, 
      color = c('#FF6B6B','#4ECDC4'), 
      main = paste('Matriz de Confusi√≥n -', best_model)
    )
    dev.off()
    cat('  ‚úì Guardado: slide12_confusion_matrix.png\n')
    
    # Curva ROC (si aplica)
    if(exists('ctrl') && ctrl$classProbs){
      probs <- predict(best_mod, newdata = test_df, type='prob')
      if(!is.null(probs) && ncol(probs)==2){
        roc_obj <- pROC::roc(response=test_df[[target_var]], predictor=probs[,2], quiet=TRUE)
        
        png(file.path(output_dir,'slide12_roc_curve.png'), width=800, height=600)
        plot(
          roc_obj, 
          main = paste('Curva ROC -', best_model),
          col = '#2C3E50',
          lwd = 2,
          print.auc = TRUE
        )
        dev.off()
        cat('  ‚úì Guardado: slide12_roc_curve.png\n')
      }
    }
    
  }, error = function(e){
    cat('  ‚ö†Ô∏è Error generando matriz/ROC:', conditionMessage(e), '\n')
  })
}

# ============================================
# 11. GR√ÅFICO DE PREDICCIONES VS REALES (Regresi√≥n)
# ============================================
if(exists('problem_type') && problem_type=='regression'){
  cat('üìä Generando gr√°fico de predicciones vs reales...\n')
  
  tryCatch({
    # Identificar mejor modelo
    if('Rsquared' %in% names(eval_df)){
      best_model <- eval_df %>% arrange(desc(Rsquared)) %>% slice(1) %>% pull(model)
    } else if('RMSE' %in% names(eval_df)){
      best_model <- eval_df %>% arrange(RMSE) %>% slice(1) %>% pull(model)
    } else {
      best_model <- eval_df$model[1]
    }
    
    cat('  Mejor modelo seg√∫n test:', best_model, '\n')
    
    best_mod <- results[[best_model]]$model
    preds <- predict(best_mod, newdata = test_df)
    
    png(file.path(output_dir,'slide12_predictions_vs_actual.png'), width=1000, height=800)
    plot(
      test_df[[target_var]], 
      preds,
      xlab = 'Valores Reales',
      ylab = 'Predicciones',
      main = paste('Predicciones vs Reales -', best_model),
      pch = 19,
      col = rgb(0, 0, 1, 0.3),
      cex = 0.8
    )
    abline(0, 1, col = 'red', lwd = 2, lty = 2)  # L√≠nea y=x
    grid()
    
    # Agregar R¬≤
    rsq <- eval_df %>% filter(model == best_model) %>% pull(Rsquared)
    legend('topleft', 
           legend = paste('R¬≤ =', round(rsq, 3)),
           bty = 'n',
           cex = 1.2)
    
    dev.off()
    cat('  ‚úì Guardado: slide12_predictions_vs_actual.png\n')
    
    # Gr√°fico de residuos
    png(file.path(output_dir,'slide12_residuals.png'), width=1000, height=800)
    residuals <- test_df[[target_var]] - preds
    plot(
      preds,
      residuals,
      xlab = 'Predicciones',
      ylab = 'Residuos',
      main = paste('An√°lisis de Residuos -', best_model),
      pch = 19,
      col = rgb(1, 0, 0, 0.3),
      cex = 0.8
    )
    abline(h = 0, col = 'blue', lwd = 2, lty = 2)
    grid()
    dev.off()
    cat('  ‚úì Guardado: slide12_residuals.png\n')
    
  }, error = function(e){
    cat('  ‚ö†Ô∏è Error generando gr√°ficos de predicci√≥n:', conditionMessage(e), '\n')
  })
}

# ============================================
# 12. SCATTER PLOT
# ============================================
cat('üìä Generando scatter plot...\n')

tryCatch({
  num_vars <- names(test_df)[sapply(test_df, is.numeric)]
  
  if(length(num_vars) >= 2){
    g_scatter <- ggplot2::ggplot(
      test_df, 
      ggplot2::aes_string(x=num_vars[1], y=num_vars[2], color=target_var)
    ) + 
      ggplot2::geom_point(alpha=0.6, size=2) + 
      ggplot2::theme_minimal() +
      ggplot2::labs(
        title = paste('Scatter Plot:', num_vars[1], 'vs', num_vars[2]),
        x = num_vars[1],
        y = num_vars[2]
      )
    
    ggplot2::ggsave(
      file.path(output_dir,'slide12_scatter.png'), 
      g_scatter, 
      width=10, 
      height=7
    )
    cat('  ‚úì Guardado: slide12_scatter.png\n')
  } else {
    cat('  ‚ö†Ô∏è No hay suficientes variables num√©ricas para scatter plot\n')
  }
}, error = function(e){
  cat('  ‚ö†Ô∏è Error generando scatter:', conditionMessage(e), '\n')
})

# ============================================
# 13. LINE PLOT TEMPORAL
# ============================================
cat('üìä Generando line plot temporal...\n')

tryCatch({
  date_cols <- names(train_df)[sapply(train_df, function(x) {
    inherits(x, 'Date') || inherits(x, 'POSIXct') || 'fecha' %in% tolower(colnames(train_df))
  })]
  
  if(length(date_cols) == 0){
    # Buscar columna que contenga 'fecha' o 'date'
    date_cols <- grep('fecha|date', names(train_df), ignore.case = TRUE, value = TRUE)
  }
  
  if(length(date_cols) > 0){
    num_vars <- names(train_df)[sapply(train_df, is.numeric)]
    
    if(length(num_vars) > 0){
      dcol <- date_cols[1]
      vcol <- num_vars[1]
      
      # Convertir a fecha si no lo es
      tmp <- train_df
      if(!inherits(tmp[[dcol]], 'Date')){
        tmp[[dcol]] <- lubridate::ymd(as.character(tmp[[dcol]]))
      }
      
      tmp <- tmp %>% 
        filter(!is.na(.data[[dcol]])) %>%
        rename(date_col = !!dcol, value_col = !!vcol)
      
      if(nrow(tmp) > 0){
        g_line <- tmp %>% 
          group_by(date_col) %>% 
          summarize(meanval = mean(value_col, na.rm=TRUE), .groups='drop') %>%
          ggplot2::ggplot(ggplot2::aes(x=date_col, y=meanval)) + 
          ggplot2::geom_line(color='steelblue', size=1) + 
          ggplot2::geom_point(color='darkblue', size=2) +
          ggplot2::theme_minimal() + 
          ggplot2::labs(
            title = paste('Evoluci√≥n Temporal de', vcol),
            x = 'Fecha',
            y = paste('Media de', vcol)
          )
        
        ggplot2::ggsave(
          file.path(output_dir,'slide12_lineplot.png'), 
          g_line, 
          width=12, 
          height=6
        )
        cat('  ‚úì Guardado: slide12_lineplot.png\n')
      }
    }
  } else {
    cat('  ‚ö†Ô∏è No se encontr√≥ columna de fecha para line plot\n')
  }
}, error = function(e){
  cat('  ‚ö†Ô∏è Error generando line plot:', conditionMessage(e), '\n')
})

# ============================================
# 14. FEATURE IMPORTANCE (si aplica)
# ============================================
cat('üìä Generando gr√°fico de importancia de variables...\n')

if('rf' %in% names(results)){
  tryCatch({
    rf_model <- results$rf$model$finalModel
    
    if(!is.null(rf_model$importance)){
      png(file.path(output_dir,'slide13_feature_importance.png'), width=1200, height=800)
      
      importance_df <- as.data.frame(rf_model$importance)
      importance_df$feature <- rownames(importance_df)
      
      # Usar primera columna de importancia
      imp_col <- names(importance_df)[1]
      importance_df <- importance_df[order(importance_df[[imp_col]], decreasing=TRUE), ]
      importance_df <- head(importance_df, 20)  # Top 20
      
      par(mar=c(5,10,4,2))
      barplot(
        importance_df[[imp_col]],
        names.arg = importance_df$feature,
        las = 2,
        horiz = TRUE,
        col = rainbow(nrow(importance_df)),
        main = 'Top 20 Variables M√°s Importantes (Random Forest)',
        xlab = imp_col,
        cex.names = 0.7
      )
      
      dev.off()
      cat('  ‚úì Guardado: slide13_feature_importance.png\n')
    }
  }, error = function(e){
    cat('  ‚ö†Ô∏è Error generando feature importance:', conditionMessage(e), '\n')
  })
}

# ============================================
# 15. CONCLUSIONES AUTOM√ÅTICAS
# ============================================
cat('üìù Generando conclusiones...\n')

# Identificar mejor modelo
if(exists('problem_type') && problem_type == 'classification'){
  if('Accuracy' %in% names(eval_df)){
    best_model <- eval_df %>% arrange(desc(Accuracy)) %>% slice(1)
    metric_name <- 'Accuracy'
    metric_value <- best_model$Accuracy
  } else {
    best_model <- eval_df[1, ]
    metric_name <- names(eval_df)[2]
    metric_value <- best_model[[2]]
  }
} else {
  if('Rsquared' %in% names(eval_df)){
    best_model <- eval_df %>% arrange(desc(Rsquared)) %>% slice(1)
    metric_name <- 'R¬≤'
    metric_value <- best_model$Rsquared
  } else if('RMSE' %in% names(eval_df)){
    best_model <- eval_df %>% arrange(RMSE) %>% slice(1)
    metric_name <- 'RMSE'
    metric_value <- best_model$RMSE
  } else {
    best_model <- eval_df[1, ]
    metric_name <- names(eval_df)[2]
    metric_value <- best_model[[2]]
  }
}

conclusions <- c(
  paste('=== CONCLUSIONES DEL AN√ÅLISIS ==='),
  '',
  paste('Se entrenaron', length(results), 'modelos de Machine Learning:'),
  paste(' -', paste(names(results), collapse = ', ')),
  '',
  paste('MEJOR MODELO:', best_model$model),
  paste(' -', metric_name, ':', round(metric_value, 4)),
  '',
  'HALLAZGOS PRINCIPALES:',
  if(problem_type == 'classification'){
    paste('- El modelo', best_model$model, 'logr√≥ una precisi√≥n de', 
          round(metric_value*100, 2), '% en el conjunto de prueba.')
  } else {
    paste('- El modelo', best_model$model, 'explica', 
          round(metric_value*100, 2), '% de la varianza en los datos.')
  },
  '- La paralelizaci√≥n permiti√≥ entrenar m√∫ltiples modelos eficientemente.',
  '- El preprocesamiento (escalado, imputaci√≥n) fue cr√≠tico para el rendimiento.',
  '',
  'RECOMENDACIONES:',
  '- Implementar el modelo en producci√≥n con monitoreo continuo.',
  '- Reentrenar peri√≥dicamente con datos actualizados.',
  '- Considerar ensemble methods para mejorar robustez.'
)

readr::write_lines(conclusions, file.path(output_dir,'slide14_conclusions.txt'))
cat('  ‚úì Guardado: slide14_conclusions.txt\n')

# ============================================
# 16. REFERENCIAS
# ============================================
refs <- c(
  '=== REFERENCIAS BIBLIOGR√ÅFICAS ===',
  '',
  'Hastie, T., Tibshirani, R., & Friedman, J. (2009).',
  '  The Elements of Statistical Learning: Data Mining, Inference, and Prediction.',
  '  Springer Series in Statistics.',
  '',
  'James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013).',
  '  An Introduction to Statistical Learning with Applications in R.',
  '  Springer.',
  '',
  'Kuhn, M., & Johnson, K. (2013).',
  '  Applied Predictive Modeling.',
  '  Springer.',
  '',
  'Kuhn, M. (2008).',
  '  Building Predictive Models in R Using the caret Package.',
  '  Journal of Statistical Software, 28(5), 1-26.',
  '',
  'Breiman, L. (2001).',
  '  Random Forests.',
  '  Machine Learning, 45(1), 5-32.',
  '',
  'Cortes, C., & Vapnik, V. (1995).',
  '  Support-Vector Networks.',
  '  Machine Learning, 20(3), 273-297.',
  '',
  'Goodfellow, I., Bengio, Y., & Courville, A. (2016).',
  '  Deep Learning.',
  '  MIT Press.'
)

readr::write_lines(refs, file.path(output_dir,'slide15_references.txt'))
cat('  ‚úì Guardado: slide15_references.txt\n')

# ============================================
# 17. LIMITACIONES Y MEJORAS
# ============================================
improv <- c(
  '=== LIMITACIONES Y MEJORAS POTENCIALES ===',
  '',
  'LIMITACIONES IDENTIFICADAS:',
  '',
  '1. Tama√±o de Muestra:',
  paste('   - Se utilizaron', nrow(train_df), 'observaciones de entrenamiento.'),
  '   - Un dataset m√°s grande podr√≠a mejorar la generalizaci√≥n.',
  '',
  '2. Feature Engineering:',
  '   - Se utilizaron las features originales sin transformaciones complejas.',
  '   - Podr√≠an explorarse interacciones entre variables.',
  '',
  '3. Hiperpar√°metros:',
  '   - Se us√≥ un grid de b√∫squeda limitado por tiempo computacional.',
  '   - Grid search exhaustivo o bayesian optimization podr√≠an mejorar resultados.',
  '',
  '4. Validaci√≥n:',
  '   - Se us√≥ validaci√≥n cruzada de 3 folds.',
  '   - M√°s folds o validaci√≥n temporal podr√≠an ser m√°s robustos.',
  '',
  'MEJORAS PROPUESTAS:',
  '',
  '1. Preprocesamiento Avanzado:',
  '   - Imputaci√≥n multivariada (MICE, KNN imputation).',
  '   - Detecci√≥n y tratamiento de outliers m√°s sofisticado.',
  '   - Feature selection mediante importancia de variables.',
  '',
  '2. Modelos Adicionales:',
  '   - XGBoost o LightGBM (gradient boosting moderno).',
  '   - Stacking/blending de modelos.',
  '   - Deep learning si el dataset crece significativamente.',
  '',
  '3. Optimizaci√≥n:',
  '   - Hyperparameter tuning con Bayesian Optimization.',
  '   - AutoML frameworks (H2O, TPOT).',
  '   - Calibraci√≥n de probabilidades para clasificaci√≥n.',
  '',
  '4. Implementaci√≥n:',
  '   - Pipeline reproducible con tidymodels.',
  '   - Containerizaci√≥n (Docker) para deployment.',
  '   - API REST para predicciones en tiempo real.',
  '   - Dashboard interactivo (Shiny, Dash).'
)

readr::write_lines(improv, file.path(output_dir,'slide16_deficiencies.txt'))
cat('  ‚úì Guardado: slide16_deficiencies.txt\n')

# ============================================
# RESUMEN FINAL
# ============================================
cat('\n========================================\n')
cat('‚úÖ EVALUACI√ìN Y GR√ÅFICAS COMPLETADAS\n')
cat('========================================\n\n')

cat('Archivos generados en:', output_dir, '\n\n')

all_files <- list.files(output_dir, recursive = TRUE)
cat('Total de archivos:', length(all_files), '\n')
cat('\nCSVs:\n')
print(all_files[grepl('\\.csv$', all_files)])
cat('\nGr√°ficos PNG:\n')
print(all_files[grepl('\\.png$', all_files)])
cat('\nTextos:\n')
print(all_files[grepl('\\.txt$', all_files)])
cat('\nModelos RDS:\n')
print(all_files[grepl('\\.rds$', all_files)])

cat('\n========================================\n')
